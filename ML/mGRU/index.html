<!DOCTYPE html><html><head><meta name="generator" content="Hexo 3.9.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>快手语音处理单元mGRU | 给荔枝打气</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/8.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/img/iconL.png"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"><script><!-- hexo-inject:begin --><!-- hexo-inject:end -->var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = 'https://hm.baidu.com/hm.js?' + '9v8oIeMvyrTiR5LW';
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
  })();
  </script><!-- hexo-inject:begin --><!-- hexo-inject:end --></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">快手语音处理单元mGRU</h1><a id="logo" href="/.">给荔枝打气</a><p class="description"></p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">快手语音处理单元mGRU</h1><div class="post-meta">Sep 17, 2018<span> | </span><span class="category"><a href="/categories/ML/">ML</a></span><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> 阅读</span></span></div><div class="post-content"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>快手本次在Interspeech 2018上的文章基于<strong>GRU</strong>提出了新的RNN单元<strong>mGRU</strong>及其变体<strong>mGRUIP</strong>，来又快又准的处理语音信息。</p>
<!-- hexo-inject:begin --><!-- hexo-inject:end --><p>论文：<a href="https://arxiv.org/abs/1805.07024" target="_blank" rel="noopener">Gated Recurrent Unit Based Acoustic Modeling with Future Context</a></p>
<a id="more"></a>
<p>原文摘要：</p>
<blockquote>
<p>The use of future contextual information is typically shown to be helpful for acoustic modeling. However, for the recurrent neural network (RNN), <strong>it’s not so easy to model the future temporal context effectively, meanwhile keep lower model latency</strong>. In this paper, we attempt to design a RNN acoustic model that being capable of utilizing the <strong>future context effectively and directly</strong>, with the model latency and computation cost as low as possible. The proposed model is based on the <strong>minimal gated recurrent unit (mGRU)</strong> with an input projection layer inserted in it. Two context modules, <strong>temporal encoding</strong> and <strong>temporal convolution</strong>, are specifically designed for this architecture to model the future context. Experimental results on the Switchboard task and an internal Mandarin ASR task show that, the proposed model performs much better than long short-term memory (LSTM) and mGRU models, whereas enables online decoding with a maximum latency of 170 ms. This model even outperforms a very strong baseline, TDNN-LSTM, with smaller model latency and almost half less parameters.</p>
</blockquote>
<p>重点：</p>
<ul>
<li>提出了一种能利用<strong>下文信息</strong>的门控循环单元，同时保持模型的低延迟性。</li>
<li>采用了只包含更新门的最小门控循环单元（mGRU）</li>
<li>提出了两种上下文模块，时间编码和时间卷积</li>
</ul>
<p>在处理语音信息中，利用下文信息在语音识别和关键词识别等任务中非常重要，很多时候语音识别不能仅考虑当前话语的信息，我们还需要一定长度的后文信息才能降低口音和连读等协同发音的影响。 但是这里存在一个问题是，语音处理需要<strong>快</strong>，如果采用一般的双向LSTM，延迟太大了，因为需要等一个句子说完才能反向过程，这样延迟是整句话，显然行不通。</p>
<p>所以，为了降低延迟并提高计算效率，快手的李杰博士等修改基础的GRU单元，添加上下文，提出只包含更新门的最小门控循环单元mGRU(minimal gated recurrent unit)。进一步地，为了减少模型参数和计算量，他们在mGRU中加入了一个降维特征映射层，提出了mGRUIP（input projection layer），先将高维特征压缩为低维，然后在低维特征上发生实际的运算，再恢复到应有的高维特征。</p>
<p>下面具体对这两个模型进行介绍</p>
<h1 id="GRU"><a href="#GRU" class="headerlink" title="GRU"></a>GRU</h1><p><img src="https://picbed-1252770021.cos.ap-chengdu.myqcloud.com/GRU.png" alt="GRU模型结构"><br><img src="https://picbed-1252770021.cos.ap-chengdu.myqcloud.com/GRU_math.png" alt="GRU更新公式"></p>
<h1 id="mGRU"><a href="#mGRU" class="headerlink" title="mGRU"></a>mGRU</h1><p><img src="https://picbed-1252770021.cos.ap-chengdu.myqcloud.com/mGRU.PNG" alt="mGRU更新公式"></p>
<p>mGRU舍弃了重置门，将更新门中tanh换成了RuLU, 相当于令 GRU 中的重置门恒等于 1。</p>
<p>但是如果网络的每一层神经元都非常多，那么 mGRU 的计算量还是非常大，且随着神经元数量的增加计算成线性增长。这就限制了 mGRU 在大型网络和大规模场景中的应用。因此李杰等研究者进一步提出了带输入映射的 mGRUIP。</p>
<h1 id="mGRUIP"><a href="#mGRUIP" class="headerlink" title="mGRUIP"></a>mGRUIP</h1><p><img src="https://picbed-1252770021.cos.ap-chengdu.myqcloud.com/mGRUIP.PNG" alt="mGRUIP更新公式"></p>
<p>直观的给出这两种单元的结构示意图<br><img src="https://picbed-1252770021.cos.ap-chengdu.myqcloud.com/mGRU+mGRUIP.jpg" alt></p>
<p>以上还OK，接下来将上下文信息加入mGRUIP让我耳目一新，开了思路<br>在文中，提出两种上下文模块（下文？）：时间编码和时间卷积。</p>
<p>先说时间编码，未来帧的语境信息会编码为定长的表征并添加到输入映射层中，以下是其模型结构<br><img src="https://picbed-1252770021.cos.ap-chengdu.myqcloud.com/mGRUIP_temporal.jpg" alt><br>每个单元，代表一帧，它接受K步未来帧的信息，这个过程类似LSTM和CRF，通过K阶关系来降低延迟（相比于整个句子，延迟是无法避免的）。这里厉害之处在于想到这样的单元连接关系来建议依赖，开了思路了。<br>如上所示转换函数 $f(x)$ 一般可以是数乘、矩阵乘法或者是恒等函数，但快手在实验中发现恒等函数在性能上要更好一些，所以它们选择了<br>$f(x)=x$，不做处理直接相加。</p>
<p>然后是时间卷积，时间卷积修改其实是上文的转换函数$f(x)$，将所需要的前层输出拼接在一起，通过一个映射层来得到结果。具体如下<br><img src="https://picbed-1252770021.cos.ap-chengdu.myqcloud.com/mGRUIP_convolution.jpg" alt></p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>这种横向连接多个GRU单元的模式，我在图半监督节点分类的任务重也使用过，提出了GraphGRU, 也是汇聚周围的k阶信息，但是我仅仅只用了加权求和，也考虑过attention，但是会增加计算量，没有像这篇文章做得深究这一块，惭愧。其次，GRU单元的设计也不拘一格，门该减就得减，这也是我一直疑惑的地方，一个门足够了，涨知识了。</p>
</div><div><ul class="post-copyright"><li class="post-copyright-author"><strong>本文作者：</strong>zeki</li><li class="post-copyright-link"><strong>本文链接：</strong><a href="/ML/mGRU/">https://zekizz.github.io/ML/mGRU/</a></li><li class="post-copyright-license"><strong>版权声明：</strong>本博客所有文章除特别声明外均为博主原创，转载请注明出处！</li></ul></div><br><div class="tags"><a href="/tags/machine-learning/">machine learning</a><a href="/tags/语音处理/">语音处理</a></div><div class="post-nav"><a class="pre" href="/Blog/install-hexo-blog/">hexo搭建github个人博客简明教程</a><a class="next" href="/ML/graph-based-semi-supervised-classification_0/">图半监督节点分类之零——前言</a></div><div id="lv-container" data-id="city" data-uid="MTAyMC80NzQ1Ni8yMzk1Ng=="><script>(function(d, s) {
   var j, e = d.getElementsByTagName(s)[0];
   if (typeof LivereTower === 'function') { return; }
   j = d.createElement(s);
   j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
   j.async = true;
   e.parentNode.insertBefore(j, e);
})(document, 'script');
</script></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"><input type="hidden" name="sitesearch" value="https://zekizz.github.io"></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Blog/">Blog</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/ML/">ML</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/NLP/">NLP</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/NLU/">NLU</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/git/">git</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/html/">html</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/others/">others</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/python/">python</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/visualisation/">visualisation</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/心情/">心情</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/推荐系统/">推荐系统</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/machine-learning/" style="font-size: 15px;">machine learning</a> <a href="/tags/深度学习/" style="font-size: 15px;">深度学习</a> <a href="/tags/NLP/" style="font-size: 15px;">NLP</a> <a href="/tags/NER/" style="font-size: 15px;">NER</a> <a href="/tags/python/" style="font-size: 15px;">python</a> <a href="/tags/数据结构/" style="font-size: 15px;">数据结构</a> <a href="/tags/git/" style="font-size: 15px;">git</a> <a href="/tags/graph-embedding/" style="font-size: 15px;">graph embedding</a> <a href="/tags/半监督分类/" style="font-size: 15px;">半监督分类</a> <a href="/tags/CRF/" style="font-size: 15px;">CRF</a> <a href="/tags/excel/" style="font-size: 15px;">excel</a> <a href="/tags/RNN/" style="font-size: 15px;">RNN</a> <a href="/tags/概率图模型/" style="font-size: 15px;">概率图模型</a> <a href="/tags/html/" style="font-size: 15px;">html</a> <a href="/tags/前端/" style="font-size: 15px;">前端</a> <a href="/tags/博客/" style="font-size: 15px;">博客</a> <a href="/tags/语音处理/" style="font-size: 15px;">语音处理</a> <a href="/tags/推荐系统/" style="font-size: 15px;">推荐系统</a> <a href="/tags/文本处理/" style="font-size: 15px;">文本处理</a> <a href="/tags/甜/" style="font-size: 15px;">甜</a> <a href="/tags/可视化/" style="font-size: 15px;">可视化</a> <a href="/tags/文件/" style="font-size: 15px;">文件</a> <a href="/tags/multi-label/" style="font-size: 15px;">multi-label</a> <a href="/tags/sklearn/" style="font-size: 15px;">sklearn</a> <a href="/tags/NLU/" style="font-size: 15px;">NLU</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/ML/sklearn-multi-label/">考虑未定义类型的多分类</a></li><li class="post-list-item"><a class="post-list-link" href="/visualisation/vue文件上传下载/">vue文件上传下载</a></li><li class="post-list-item"><a class="post-list-link" href="/NLU/nlu-survey/">NLU调研</a></li><li class="post-list-item"><a class="post-list-link" href="/python/configparse/">configparser配置解析</a></li><li class="post-list-item"><a class="post-list-link" href="/others/excel_trick/">excel去除文本中的不可打印字符</a></li><li class="post-list-item"><a class="post-list-link" href="/git/git_notes/">git笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/NLP/information-extraction/">基于句法依存树的信息抽取</a></li><li class="post-list-item"><a class="post-list-link" href="/ML/imblanced-samples/">样本类别不均衡处理</a></li><li class="post-list-item"><a class="post-list-link" href="/html/html-tag/">html自定义标签</a></li><li class="post-list-item"><a class="post-list-link" href="/html/web-space/">网页文本中空格</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://blog.csdn.net/crystal_zero" title="zeki的csdn" target="_blank">zeki的csdn</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer"><span id="busuanzi_container_site_pv">本站总访问量<span id="busuanzi_value_site_pv"></span>次</span>
<span id="busuanzi_container_site_uv">总访客<span id="busuanzi_value_site_uv"></span>人</span>
<br>Copyright © 2019 <a href="/." rel="nofollow">给荔枝打气.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.css"><!-- MathJax配置，可通过单美元符号书写行内公式等 --><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
  inlineMath: [['$','$'], ['\\(','\\)']],
  processEscapes: true,
  ignoreClass: "tex2jax_ignore|dno",
  skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  TeX: {
  equationNumbers: { autoNumber: "AMS" },
  noUndefined: {attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" }},
  Macros: {href: "{}"}
  },
  messageStyle: "none",
  "HTML-CSS": {
  preferredFont: "TeX",
  availableFonts: ["STIX","TeX"],
  linebreaks: { automatic:true },
  EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50) 
  }
  });
</script><!-- 给MathJax元素添加has-jax class --><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
 var all = MathJax.Hub.getAllJax(), i;
 for(i=0; i < all.length; i += 1) {
   all[i].SourceElement().parentNode.className += ' has-jax';
   }
 });
</script><!-- script(type='text/javascript', src='https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML') --><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"log":false,"model":{"jsonPath":"/live2dw/assets/kanzaki.model.json"},"display":{"position":"right","width":150,"height":300,"hOffset":150,"vOffset":-20},"mobile":{"show":true},"react":{"opacity":0.9}});</script><!-- hexo-inject:begin --><!-- hexo-inject:end --></body></html>